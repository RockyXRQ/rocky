<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

    <title>Rocky Xu</title>

    <meta name="author" content="Rocky Xu" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <link rel="stylesheet" type="text/css" href="stylesheet.css" />
    <link
      rel="icon"
      href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"
    />
  </head>

  <body>
    <table
      style="
        width: 100%;
        max-width: 800px;
        border: 0px;
        border-spacing: 0px;
        border-collapse: separate;
        margin-right: auto;
        margin-left: auto;
      "
    >
      <tbody>
        <tr style="padding: 0px">
          <td style="padding: 0px">
            <table
              style="
                width: 100%;
                border: 0px;
                border-spacing: 0px;
                border-collapse: separate;
                margin-right: auto;
                margin-left: auto;
              "
            >
              <tbody>
                <tr style="padding: 0px">
                  <td style="padding: 2.5%; width: 63%; vertical-align: middle">
                    <p style="text-align: center">
                      <name>ËÆ∏ Ëã•Áê™</name>
                    </p>
                    <p>
                      <a href="test"><strong>English Version</strong></a>
                    </p>
                    <p>
                      Êú¨‰∫∫‰∏∫<a href="https://www.usst.edu.cn/main.htm"
                        >‰∏äÊµ∑ÁêÜÂ∑•Â§ßÂ≠¶</a
                      >Ëá™Âä®Âåñ‰∏ì‰∏öÊú¨ÁßëÂ∫îÂ±äÁîüÔºåÁé∞ÊãÖ‰ªªÂπøÂ∑û<a
                        href="https://www.firstinspires.org/robotics/frc"
                        >FRC(First Robotics Competition)
                      </a>
                      Èòü‰ºç 8583 Juggernauts Âíå 8214 Cyber Unicorn
                      ÁÆóÊ≥ïÁªÑÂØºÂ∏àÔºåÊìÖÈïøÈ¢ÜÂüü‰∏∫Êú∫Âô®‰∫∫Â≠¶ÔºåÊéßÂà∂ÁêÜËÆ∫„ÄÇ
                    </p>
                    <p style="text-align: center">
                      <a href="mailto:rocky_xrq@qq.com">ÁîµÂ≠êÈÇÆÁÆ±</a> &nbsp/&nbsp
                      <a href="https://github.com/jonbarron/">Github</a>
                      &nbsp/&nbsp
                      <a
                        href="https://www.linkedin.cn/incareer/in/ruoqi-xu-b79094259"
                        >È¢ÜËã±</a
                      >
                    </p>
                  </td>
                  <td style="padding: 2.0%; width: 35%; max-width: 35%">
                    <a href="images/me_1_circle_shadow.jpg"
                      ><img
                        style="width: 100%; max-width: 100%"
                        alt="profile photo"
                        src="images/me_1_circle_shadow.jpg"
                        class="hoverZoomLink"
                    /></a>
                  </td>
                </tr>
              </tbody>
            </table>
            <table
              style="
                width: 100%;
                border: 0px;
                border-spacing: 0px;
                border-collapse: separate;
                margin-right: auto;
                margin-left: auto;
              "
            >
              <tbody>
                <tr>
                  <td
                    style="padding: 20px; width: 100%; vertical-align: middle"
                  >
                    <heading>Research</heading>
                    <p>
                      I'm interested in computer vision, machine learning,
                      optimization, and image processing. Much of my research is
                      about inferring the physical world (shape, motion, color,
                      light, etc) from images. Representative papers are
                      <span class="highlight">highlighted</span>.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>
            <table
              style="
                width: 100%;
                border: 0px;
                border-spacing: 0px;
                border-collapse: separate;
                margin-right: auto;
                margin-left: auto;
              "
            >
              <tbody>
                <tr onmouseout="mira_stop()" onmouseover="mira_start()">
                  <td style="padding: 20px; width: 25%; vertical-align: middle">
                    <div class="one">
                      <div class="two" id="mira_image">
                        <img src="images/mira_after.jpg" width="160" />
                      </div>
                      <img src="images/mira_before.jpg" width="160" />
                    </div>
                    <script type="text/javascript">
                      function mira_start() {
                        document.getElementById("mira_image").style.opacity =
                          "1";
                      }

                      function mira_stop() {
                        document.getElementById("mira_image").style.opacity =
                          "0";
                      }
                      mira_stop();
                    </script>
                  </td>
                  <td style="padding: 20px; width: 75%; vertical-align: middle">
                    <a href="https://openreview.net/forum?id=AmPeAFzU3a4">
                      <papertitle
                        >MIRA: Mental Imagery for Robotic
                        Affordances</papertitle
                      >
                    </a>
                    <br />
                    <a href="https://yenchenlin.me/">Lin Yen-Chen</a>,
                    <a href="http://www.peteflorence.com/">Pete Florence</a>,
                    <a href="https://andyzeng.github.io/">Andy Zeng</a>,
                    <strong>Jonathan T. Barron</strong>,
                    <a href="https://yilundu.github.io/">Yilun Du</a>,
                    <a href="https://people.csail.mit.edu/weichium/"
                      >Wei-Chiu Ma</a
                    >,
                    <a href="https://anthonysimeonov.github.io/"
                      >Anthony Simeonov</a
                    >,
                    <a
                      href="https://meche.mit.edu/people/faculty/ALBERTOR@MIT.EDU"
                      >Alberto Rodriguez</a
                    >,
                    <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>
                    <br />
                    <em>CoRL</em>, 2022
                    <p></p>
                    <p>
                      NeRF lets us synthesize novel orthographic views that work
                      well with pixel-wise algorithms for robotic manipulation.
                    </p>
                  </td>
                </tr>

                <tr
                  onmouseout="dreamfusion_stop()"
                  onmouseover="dreamfusion_start()"
                  bgcolor="#ffffd0"
                >
                  <td style="padding: 20px; width: 25%; vertical-align: middle">
                    <div class="one">
                      <div class="two" id="dreamfusion_image">
                        <video width="100%" height="100%" muted autoplay loop>
                          <source
                            src="images/dreamfusion.mp4"
                            type="video/mp4"
                          />
                          Your browser does not support the video tag.
                        </video>
                      </div>
                      <img src="images/dreamfusion.jpg" width="160" />
                    </div>
                    <script type="text/javascript">
                      function dreamfusion_start() {
                        document.getElementById(
                          "dreamfusion_image"
                        ).style.opacity = "1";
                      }

                      function dreamfusion_stop() {
                        document.getElementById(
                          "dreamfusion_image"
                        ).style.opacity = "0";
                      }
                      dreamfusion_stop();
                    </script>
                  </td>
                  <td style="padding: 20px; width: 75%; vertical-align: middle">
                    <a href="https://dreamfusion3d.github.io/">
                      <papertitle
                        >DreamFusion: Text-to-3D using 2D Diffusion</papertitle
                      >
                    </a>
                    <br />
                    <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>,
                    <a href="https://www.ajayj.com/">Ajay Jain</a>,
                    <strong>Jonathan T. Barron</strong>,
                    <a href="https://bmild.github.io/">Ben Mildenhall</a>
                    <br />
                    <em>arXiv</em>, 2022
                    <br />
                    <a href="https://dreamfusion3d.github.io/">project page</a>
                    /
                    <a href="https://arxiv.org/abs/2209.14988">arXiv</a>
                    /
                    <a href="https://dreamfusion3d.github.io/gallery.html"
                      >gallery</a
                    >
                    <p></p>
                    <p>
                      We optimize a NeRF from scratch using a pretrained
                      text-to-image diffusion model to do text-to-3D generative
                      modeling.
                    </p>
                  </td>
                </tr>

                <tr
                  onmouseout="refnerf_stop()"
                  onmouseover="refnerf_start()"
                  bgcolor="#ffffd0"
                >
                  <td style="padding: 20px; width: 25%; vertical-align: middle">
                    <div class="one">
                      <div class="two" id="refnerf_image">
                        <video width="100%" height="100%" muted autoplay loop>
                          <source src="images/refnerf.mp4" type="video/mp4" />
                          Your browser does not support the video tag.
                        </video>
                      </div>
                      <img src="images/refnerf.jpg" width="160" />
                    </div>
                    <script type="text/javascript">
                      function refnerf_start() {
                        document.getElementById("refnerf_image").style.opacity =
                          "1";
                      }

                      function refnerf_stop() {
                        document.getElementById("refnerf_image").style.opacity =
                          "0";
                      }
                      refnerf_stop();
                    </script>
                  </td>
                  <td style="padding: 20px; width: 75%; vertical-align: middle">
                    <a href="https://dorverbin.github.io/refnerf/index.html">
                      <papertitle
                        >Ref-NeRF: Structured View-Dependent Appearance for
                        Neural Radiance Fields</papertitle
                      >
                    </a>
                    <br />
                    <a href="https://scholar.harvard.edu/dorverbin/home"
                      >Dor Verbin</a
                    >, <a href="https://phogzone.com/">Peter Hedman</a>,
                    <a href="https://bmild.github.io/">Ben Mildenhall</a>,
                    <br />
                    <a href="Todd Zickler">Todd Zickler</a>,
                    <strong>Jonathan T. Barron</strong>,
                    <a href="https://pratulsrinivasan.github.io/"
                      >Pratul Srinivasan</a
                    >
                    <br />
                    <em>CVPR</em>, 2022 &nbsp
                    <font color="red"
                      ><strong
                        >(Oral Presentation, Best Student Paper Honorable
                        Mention)</strong
                      ></font
                    >
                    <br />
                    <a href="https://dorverbin.github.io/refnerf/index.html"
                      >project page</a
                    >
                    /
                    <a href="https://arxiv.org/abs/2112.03907">arXiv</a>
                    /
                    <a href="https://youtu.be/qrdRH9irAlk">video</a>
                    <p></p>
                    <p>
                      Explicitly modeling reflections in NeRF produces realistic
                      shiny surfaces and accurate surface normals, and lets you
                      edit materials.
                    </p>
                  </td>
                </tr>

                <tr
                  onmouseout="mip360_stop()"
                  onmouseover="mip360_start()"
                  bgcolor="#ffffd0"
                >
                  <td style="padding: 20px; width: 25%; vertical-align: middle">
                    <div class="one">
                      <div class="two" id="mip360_image">
                        <video width="100%" height="100%" muted autoplay loop>
                          <source
                            src="images/mip360_sat.mp4"
                            type="video/mp4"
                          />
                          Your browser does not support the video tag.
                        </video>
                      </div>
                      <img src="images/mip360_sat.jpg" width="160" />
                    </div>
                    <script type="text/javascript">
                      function mip360_start() {
                        document.getElementById("mip360_image").style.opacity =
                          "1";
                      }

                      function mip360_stop() {
                        document.getElementById("mip360_image").style.opacity =
                          "0";
                      }
                      mip360_stop();
                    </script>
                  </td>
                  <td style="padding: 20px; width: 75%; vertical-align: middle">
                    <a href="http://jonbarron.info/mipnerf360">
                      <papertitle
                        >Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance
                        Fields</papertitle
                      >
                    </a>
                    <br />
                    <strong>Jonathan T. Barron</strong>,
                    <a href="https://bmild.github.io/">Ben Mildenhall</a>,
                    <a href="https://scholar.harvard.edu/dorverbin/home"
                      >Dor Verbin</a
                    >,
                    <a href="https://pratulsrinivasan.github.io/"
                      >Pratul Srinivasan</a
                    >,
                    <a href="https://phogzone.com/">Peter Hedman</a>
                    <br />
                    <em>CVPR</em>, 2022 &nbsp
                    <font color="red"
                      ><strong>(Oral Presentation)</strong></font
                    >
                    <br />
                    <a href="http://jonbarron.info/mipnerf360">project page</a>
                    /
                    <a href="https://arxiv.org/abs/2111.12077">arXiv</a>
                    /
                    <a href="https://youtu.be/zBSH-k9GbV4">video</a>
                    <p></p>
                    <p>
                      mip-NeRF can be extended to produce realistic results on
                      unbounded scenes.
                    </p>
                  </td>
                </tr>

                <tr
                  onmouseout="rawnerf_stop()"
                  onmouseover="rawnerf_start()"
                  bgcolor="#ffffd0"
                >
                  <td style="padding: 20px; width: 25%; vertical-align: middle">
                    <div class="one">
                      <div class="two" id="rawnerf_image">
                        <video width="100%" height="100%" muted autoplay loop>
                          <source src="images/rawnerf.mp4" type="video/mp4" />
                          Your browser does not support the video tag.
                        </video>
                      </div>
                      <img src="images/rawnerf.jpg" width="160" />
                    </div>
                    <script type="text/javascript">
                      function rawnerf_start() {
                        document.getElementById("rawnerf_image").style.opacity =
                          "1";
                      }

                      function rawnerf_stop() {
                        document.getElementById("rawnerf_image").style.opacity =
                          "0";
                      }
                      rawnerf_stop();
                    </script>
                  </td>
                  <td style="padding: 20px; width: 75%; vertical-align: middle">
                    <a href="https://bmild.github.io/rawnerf/index.html">
                      <papertitle
                        >NeRF in the Dark: High Dynamic Range View Synthesis
                        from Noisy Raw Images</papertitle
                      >
                    </a>
                    <br />
                    <a href="https://bmild.github.io/">Ben Mildenhall</a>,
                    <a href="https://phogzone.com/">Peter Hedman</a>,
                    <a href="http://www.ricardomartinbrualla.com/"
                      >Ricardo Martin-Brualla</a
                    >, <br />
                    <a href="https://pratulsrinivasan.github.io/"
                      >Pratul Srinivasan</a
                    >,
                    <strong>Jonathan T. Barron</strong>
                    <br />
                    <em>CVPR</em>, 2022 &nbsp
                    <font color="red"
                      ><strong>(Oral Presentation)</strong></font
                    >
                    <br />
                    <a href="https://bmild.github.io/rawnerf/index.html"
                      >project page</a
                    >
                    /
                    <a href="https://arxiv.org/abs/2111.13679">arXiv</a>
                    /
                    <a href="https://www.youtube.com/watch?v=JtBS4KBcKVc"
                      >video</a
                    >
                    <p></p>
                    <p>
                      Properly training NeRF on raw camera data enables HDR view
                      synthesis and bokeh, and outperforms multi-image
                      denoising.
                    </p>
                  </td>
                </tr>

                <tr onmouseout="clipnerf_stop()" onmouseover="clipnerf_start()">
                  <td style="padding: 20px; width: 25%; vertical-align: middle">
                    <div class="one">
                      <div class="two" id="clipnerf_image">
                        <video width="100%" height="100%" muted autoplay loop>
                          <source
                            src="images/dreamfield_after.mp4"
                            type="video/mp4"
                          />
                          Your browser does not support the video tag.
                        </video>
                      </div>
                      <img src="images/dreamfield_before.jpg" width="160" />
                    </div>
                    <script type="text/javascript">
                      function clipnerf_start() {
                        document.getElementById(
                          "clipnerf_image"
                        ).style.opacity = "1";
                      }

                      function clipnerf_stop() {
                        document.getElementById(
                          "clipnerf_image"
                        ).style.opacity = "0";
                      }
                      clipnerf_stop();
                    </script>
                  </td>
                  <td style="padding: 20px; width: 75%; vertical-align: middle">
                    <a href="https://ajayj.com/dreamfields">
                      <papertitle
                        >Zero-Shot Text-Guided Object Generation with Dream
                        Fields</papertitle
                      >
                    </a>
                    <br />
                    <a href="https://www.ajayj.com/">Ajay Jain</a>,
                    <a href="https://bmild.github.io/">Ben Mildenhall</a>,
                    <strong>Jonathan T. Barron</strong>,
                    <a href="https://people.eecs.berkeley.edu/~pabbeel/"
                      >Pieter Abbeel</a
                    >,
                    <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>
                    <br />
                    <em>CVPR</em>, 2022
                    <br />
                    <a href="https://ajayj.com/dreamfields">project page</a>
                    /
                    <a href="https://arxiv.org/abs/2112.01455">arXiv</a>
                    /
                    <a href="https://www.youtube.com/watch?v=1Fke6w46tv4"
                      >video</a
                    >
                    <p></p>
                    <p>
                      Supervising the CLIP embeddings of NeRF renderings lets
                      you to generate 3D objects from text prompts.
                    </p>
                  </td>
                </tr>

                <tr>
                  <td style="padding: 20px; width: 25%; vertical-align: middle">
                    <img
                      src="images/fast_texture.jpg"
                      alt="fast-texture"
                      width="160"
                      height="160"
                    />
                  </td>
                  <td width="75%" valign="middle">
                    <a
                      href="https://drive.google.com/file/d/1rc05NatkQVmUDlGCAYcHSrvAzTpU9knT/view?usp=sharing"
                    >
                      <papertitle
                        >Discovering Efficiency in Coarse-To-Fine Texture
                        Classification</papertitle
                      >
                    </a>
                    <br />
                    <strong>Jonathan T. Barron</strong>,
                    <a href="http://www.cs.berkeley.edu/~malik/"
                      >Jitendra Malik</a
                    >
                    <br />
                    <em>Technical Report</em>, 2010
                    <br />
                    <p>
                      A model and feature representation that allows for
                      sub-linear coarse-to-fine semantic segmentation.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>

            <table
              width="100%"
              align="center"
              border="0"
              cellspacing="0"
              cellpadding="20"
            >
              <tbody>
                <tr>
                  <td>
                    <heading>Misc</heading>
                  </td>
                </tr>
              </tbody>
            </table>

            <table width="100%" align="center" border="0" cellpadding="20">
              <tbody>
                <tr>
                  <td style="padding: 20px; width: 25%; vertical-align: middle">
                    <img src="images/cs188.jpg" alt="cs188" />
                  </td>
                  <td width="75%" valign="center">
                    <a
                      href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html"
                      >Graduate Student Instructor, CS188 Spring 2011</a
                    >
                    <br />
                    <a
                      href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html"
                      >Graduate Student Instructor, CS188 Fall 2010</a
                    >
                    <br />
                    <a href="http://aima.cs.berkeley.edu/"
                      >Figures, "Artificial Intelligence: A Modern Approach",
                      3rd Edition</a
                    >
                  </td>
                </tr>
              </tbody>
            </table>
          </td>
        </tr>
      </tbody>
    </table>
  </body>
</html>
